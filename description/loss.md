# loss function.py

modelì˜ parameterí•™ìŠµì„ ìœ„í•œ loss functionì„ ì •ì˜í•œë‹¤.

**total loss** = `coordinate loss` + `confidence loss` + `class loss`





##### Intersection over Union(IOU)

![img](https://t1.daumcdn.net/cfile/tistory/993477505D14A25016)

IoU = êµì§‘í•© ì˜ì—­ ë„“ì´ / í•©ì§‘í•© ì˜ì—­ ë„“ì´

best predicted bounding boxë€ ëª¨ë“  predicted bounding box ì¤‘ì—ì„œ ê°€ì¥ í° IOU ê°’ì„ ê°€ì§„ bounding boxì´ë‹¤. 



**indicator function**

S*S sizeì˜ grid cell ì¤‘ íŠ¹ì • grid cellì—ì„œ ë¯¿ì„ë§Œí•œ bounding boxë§Œ ì‚´ë¦¬ê³  ë‚˜ë¨¸ì§„ ë²„ë¦¬ëŠ” ìš©ë„ë¡œ ì‚¬ìš©ëœë‹¤.

i : ië²ˆì§¸ grid cell (0ë¶€í„° [cell]^2ê¹Œì§€)

j : j ë²ˆì§¸ detector (0ë¶€í„° [Bboxs per cell] ê¹Œì§€)

- $$
  ğŸ™^{obj}_{ij}
  $$

  i ë²ˆì§¸ grid cellì— objectê°€ ìˆê³ , í•´ë‹¹ cell ì•ˆì— jë²ˆì§¸ detectorê°€ ìˆì„ ë•Œì—ë§Œ 1ì„ return. ê·¸ ì™¸ì—ëŠ” 0

  > objectê°€ ìˆëŠ” cellì—ì„œ jë²ˆì§¸ detectorê°€ ìˆì„ ë•Œì—ë§Œ 1

  ```python
  I = iou_predict_truth 	
  max_I = tf.reduce_max(I, 2, keepdims=True)
  best_box_mask = tf.cast((I >= max_I), tf.float32
                          
  object_exists_cell = np.zeros([cell_size, cell_size, 1])
  object_exists_cell_i, object_exists_cell_j = int(cell_size * ycenter / input_height), int(cell_size * xcenter / input_width)
  object_exists_cell[object_exists_cell_i][object_exists_cell_j] = 1
                          
  object_indicator_function = best_box_mask * object_exists_cell
  ```

  

- $$
  ğŸ™^{noobj}_{ij}
  $$

  i ë²ˆì§¸ grid cellì— objectê°€ ì—†ê³ , í•´ë‹¹ cell ì•ˆì— jë²ˆì§¸ detectorê°€ ìˆì„ ë•Œì—ë§Œ 1ì„ return. ê·¸ ì™¸ì—ëŠ” 0

  > objectê°€ ì—†ëŠ” cellì—ì„œ jë²ˆì§¸ detectorê°€ ìˆì„ ë•Œì—ë§Œ 1

  ```python
  I = iou_predict_truth 	
  max_I = tf.reduce_max(I, 2, keepdims=True)
  best_box_mask = tf.cast((I >= max_I), tf.float32
                          
  object_exists_cell = np.zeros([cell_size, cell_size, 1])
  object_exists_cell_i, object_exists_cell_j = int(cell_size * ycenter / input_height), int(cell_size * xcenter / input_width)
  object_exists_cell[object_exists_cell_i][object_exists_cell_j] = 1
                          
  noobject_indicator_function = best_box_mask * (1-object_exists_cell)
  ```

  

**contents**

- [coordinate loss]("#coordinate loss")
- [confidence loss]("#confidence loss")
- [class loss]("#class loss")
- [Total loss]("#Total loss")
- [code](#code)



---



### coordinate loss

x, yì¢Œí‘œì™€ width, heightì˜ ì˜¤ì°¨ì— ëŒ€í•´ MSEë¥¼ í†µí•´ lossë¥¼ ê³„ì‚°í•œë‹¤.
$$
Coordinate\ Loss = \lambda_{coord} \sum^{S^2}_{i = 0}\sum^{B}_{j = 0}ğŸ™^{obj}_{ij}\left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right] \\
+ \lambda_{coord} \sum^{S^2}_{i = 0}\sum^{B}_{j = 0}ğŸ™^{obj}_{ij}\left[ (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right] \\
$$


```python
# predict[2] == pred_coordinate	[1, cell_size, cell_size, boxes_per_cell, 4]

predict_boxes = predict[2]
predict_boxes = tf.squeeze(predict_boxes, [0])

pred_xcenter = predict_boxes[:, :, :, 0]
pred_ycenter = predict_boxes[:, :, :, 1]
pred_sqrt_w = tf.sqrt(tf.minimum(input_width * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))
pred_sqrt_h = tf.sqrt(tf.minimum(input_height * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))
pred_sqrt_w = tf.cast(pred_sqrt_w, tf.float32)
pred_sqrt_h = tf.cast(pred_sqrt_h, tf.float32)

# parse labe
labels = np.array(labels) 
label = labels[each_object_num, :]

xcenter = label[0]
ycenter = label[1] 
sqrt_w = tf.sqrt(label[2])
sqrt_h = tf.sqrt(label[3])

coord_loss = ((tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_xcenter - xcenter) / (input_width / cell_size)) +
tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_ycenter - ycenter) / (input_height / cell_size)) + tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_sqrt_w - sqrt_w)) / input_width 
+ tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_sqrt_h - sqrt_h)) / input_height ) * coord_scale)
```



- width, heightì— Squareì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ : 

  objectì˜ í¬ê¸°ì— ë”°ë¼ì„œ bounding boxì˜ width, heightì˜ loss í¬ê¸°ê°€ ì‘ë”ë¼ë„, ë‹¤ë¥¸ lossì— ë¹„í•´ ìƒëŒ€ì ìœ¼ë¡œ í° ì°¨ì´ì²˜ëŸ¼ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— lossì— ë£¨íŠ¸ë¥¼ ì”Œìš´ë‹¤.

  > ex) 
  >
  > object 1 ì˜ label width = 300,		 object 2 ì˜ label width = 16
  >
  > object 1 ì˜ prediction width = 305,		 object 2 ì˜ prediction width = 13
  >
  > |300 - 305| =5
  >
  > |16 - 13| = 3   
  >
  > ì˜í–¥ì€ object 1ì´ ë” ì‘ì•„ì•¼ í•˜ì§€ë§Œ, ê°’ì˜ í¬ê¸°ê°€  object 2ì— ë¹„í•´ í¬ê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë¶€ë¶„ì´ í•™ìŠµì— ë°˜ì˜ë˜ì–´ ì˜ë„ì¹˜ ì•Šì€ í•™ìŠµ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.





### confidence loss

`confidence loss` = `object loss` + `noobject loss`

object lossì™€ nobject lossëŠ” objectì˜ ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¥¸ 0 or 1ì˜ í™•ë¥ ì„ ê°€ì§„ binaryí•œ í™•ë¥  ì˜ˆì¸¡ì´ê¸° ë•Œë¬¸ì— BCEë¥¼ í†µí•´ lossë¥¼ ê³„ì‚°í–ˆë‹¤.


$$
\hat{C_i} = \sigma(C_i) = \frac{1}{1+e^{-C_i}}\\
\sigma : Sigmoid,  \ \ \ \ \ C_i : label,  \ \ \ \ \ \hat{C_i} : predicted\ value
$$

$$
Object\ Loss = \lambda_{obj} * ğŸ™^{obj}_{ij} * \overline{(-[C_i*log(\hat{C_i}) + (C_i)log(1 - \hat{C_i})])} \\

NoObject\ loss =  \lambda_{noobj} * ğŸ™^{noobj}_{ij}* \overline{(-[C_i*log(\hat{C_i}) + (C_i)log(1 - \hat{C_i})])}\\
$$

```python
	# set object_loss information(confidence, objectê°€ ìˆì„ í™•ë¥ )
	C = iou_predict_truth 

	arg_c = tf.argmax(C, axis = 2)
	tmp_object= np.zeros_like(C)
	for i in range(cell_size):
		for j in range(cell_size):
			# íŠ¹ì • cellì˜ ë‘ Bboxì˜ IOUê°€ 0ì´ë©´ í•´ë‹¹ cellì˜ object labelì„ ì „ë¶€ 0ìœ¼ë¡œ ìœ ì§€
			if tf.reduce_max(C[i][j]) == 0:    	
				pass
			else :
				# ë‘ Bboxì¤‘ ë†’ì€ iouë¥¼ ê°€ì§€ë©´ 1, ì•„ë‹ˆë©´ 0ì˜ ê°’ (one_hot) 
				tmp_object[i][j][arg_c[i][j]] = 1  			
	C_label = tf.constant(tmp_object)
    
    # predict[1] == pred_confidence [1, cell_size, cell_size, boxes_per_cell]
    pred_C = predict[1]
	pred_C = tf.squeeze(pred_C, [0])

    # object_loss
	object_loss =  tf.reduce_mean(object_exists_cell * best_box_mask * object_scale * tf.nn.sigmoid_cross_entropy_with_logits(C_label, pred_C))
		
	# noobject_loss
	noobject_loss = tf.reduce_mean((1 - object_exists_cell) * best_box_mask * tf.nn.sigmoid_cross_entropy_with_logits(C_label, pred_C) * noobject_scale)
```



- ê° cellì—ì„œ ê³„ì‚° í•œ BCEê°’ì˜ í‰ê· ì¹˜ì— ë”°ë¼ backpropagationì´ ì´ë£¨ì–´ì§€ë©° í•™ìŠµ ë  ìˆ˜ ìˆë„ë¡ `tf.reduce_mean` ì„ ì‚¬ìš©í–ˆë‹¤.



### class loss

class lossëŠ” multi classì— ëŒ€í•œ í™•ë¥  ì˜ˆì¸¡ì´ê¸° ë•Œë¬¸ì— CCEë¥¼ í†µí•´ lossë¥¼ ê³„ì‚°í–ˆë‹¤.


$$
\hat{C_i} = Softmax(C_i) = \frac{e^{(C_i)}}{\sum_{j=1}^{K}e^{(C_j)}}\\
$$

$$
Class\ Loss = ğŸ™^{obj}_{i} * \overline{(- \sum_{i=1}^{K} C_i log(\hat{C}_i))}
$$



```python
	# set class_loss information(probability, íŠ¹ì • classì¼ í™•ë¥ )
    # predict[0] == pred_class 		[1, cell_size, cell_size, num_class]
	pred_P = predict[0]
	pred_P = tf.squeeze(pred_P, [0])	
	temp_P = np.zeros_like(pred_P)
	for i in range(cell_size):
		for j in range(cell_size):
				temp_P[i][j] = label[4]
	P = tf.constant(temp_P)
    
    class_loss = tf.reduce_mean(object_exists_cell * class_scale * tf.nn.softmax_cross_entropy_with_logits(P, pred_P))
```







## Total loss

**total loss** = `coordinate loss` + `confidence loss` + `class loss`
$$
Total\ loss  = 
\lambda_{coord} \sum^{S^2}_{i = 0}\sum^{B}_{j = 0}ğŸ™^{obj}_{ij}\left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right] \\
+ \lambda_{coord} \sum^{S^2}_{i = 0}\sum^{B}_{j = 0}ğŸ™^{obj}_{ij}\left[ (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right] \\
+ \lambda_{obj} * ğŸ™^{obj}_{ij} * \overline{(-[C_i*log(\hat{C_i}) + (C_i)log(1 - \hat{C_i})])} \\
+  \lambda_{noobj} * ğŸ™^{noobj}_{ij}* \overline{(-[C_i*log(\hat{C_i}) + (C_i)log(1 - \hat{C_i})])}\\
+ ğŸ™^{obj}_{i} * \overline{- \sum_{i=1}^{K} C_i log(\hat{C}_i)}
$$


### code

**description argument**

- `predict` : shape = [cell_size, cell_size, 5*boxes_per_cell + num_calsses] ì¸ tensor

- `labels` : ì „ì²´ label ì•ˆì˜ ê°ê°ì˜ label ì—ëŠ” 5ê°€ì§€ dataê°€ mappingë˜ì–´ìˆë‹¤. 

  >  shape = [number of object, [x coordinate, y coordinate, width, height, confidence ]]
  >
  > ê° coordinateëŠ” normalizeë˜ì§€ ì•Šì€ ê°’ 

- `each_object_num` : index of object

- `num_classes` : predictioní•˜ëŠ” classì˜ ê°œìˆ˜

- `boxes_per_cell` : í•˜ë‚˜ì˜ grid cellë‹¹ ì˜ˆì¸¡í•  bounding box

- `cell_size` 

- `input_width` : image width after resizing 

- `input_height` : image height after resizing 

- `coord_scale` : coefficients of coordinate loss

- `object_scale` : coefficients of object loss

- `noobject_scale` : coefficients of noobject loss

- `class_scale`  : coefficients of class loss



```python
import tensorflow as tf
import numpy as np
from utils import iou


def yolo_loss(predict,
			  labels,
			  each_object_num,
			  cell_size,
			  input_width,
			  input_height,
			  coord_scale,
			  object_scale,
			  noobject_scale,
			  class_scale):

	# predict[0] == pred_class 		[1, cell_size, cell_size, num_class]
	# predict[1] == pred_confidence [1, cell_size, cell_size, boxes_per_cell]
	# predict[2] == pred_coordinate	[1, cell_size, cell_size, boxes_per_cell, 4]
		
	predict_boxes = predict[2]
	predict_boxes = tf.squeeze(predict_boxes, [0])

	# prediction : absolute coordinate
	pred_xcenter = predict_boxes[:, :, :, 0]
	pred_ycenter = predict_boxes[:, :, :, 1]
	pred_sqrt_w = tf.sqrt(tf.minimum(input_width * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))
	pred_sqrt_h = tf.sqrt(tf.minimum(input_height * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))
	pred_sqrt_w = tf.cast(pred_sqrt_w, tf.float32)
	pred_sqrt_h = tf.cast(pred_sqrt_h, tf.float32)

	# parse labe
	labels = np.array(labels) 
	label = labels[each_object_num, :]

	xcenter = label[0]
	ycenter = label[1] 
	sqrt_w = tf.sqrt(label[2])
	sqrt_h = tf.sqrt(label[3])


	# calulate iou between ground-truth and predictions
	# ê° cellì˜ ê° Bboxì™€ labelê³¼ì˜ iouê³„ì‚° tf.shape(iou_predict_truth):, [7 7 2]
	iou_predict_truth = iou(predict_boxes, label[0:4]) 

	# find best box mask(ë‘ Bboxì¤‘ì—ì„œ IOUê°€ í° Bboxì„ íƒ)
	# ë‘ Bboxì˜ IOUê°€ ê°™ìœ¼ë©´ ì²« ë²ˆì§¸ Bboxê°€ best Bbox
	I = iou_predict_truth 	
	max_I = tf.reduce_max(I, 2, keepdims=True)
	best_box_mask = tf.cast((I >= max_I), tf.float32)
	
	# set object_loss information(confidence, objectê°€ ìˆì„ í™•ë¥ )
	C = iou_predict_truth 

	arg_c = tf.argmax(C, axis = 2)
	tmp_object= np.zeros_like(C)
	for i in range(cell_size):
		for j in range(cell_size):
			# íŠ¹ì • cellì˜ ë‘ Bboxì˜ IOUê°€ 0ì´ë©´ í•´ë‹¹ cellì˜ object labelì„ ì „ë¶€ 0ìœ¼ë¡œ ìœ ì§€
			if tf.reduce_max(C[i][j]) == 0:    	
				pass
			else :
				# ë‘ Bboxì¤‘ ë†’ì€ iouë¥¼ ê°€ì§€ë©´ 1, ì•„ë‹ˆë©´ 0ì˜ ê°’ (one_hot) 
				tmp_object[i][j][arg_c[i][j]] = 1  			
	C_label = tf.constant(tmp_object)


	pred_C = predict[1]
	pred_C = tf.squeeze(pred_C, [0])
	
	# set class_loss information(probability, íŠ¹ì • classì¼ í™•ë¥ )
	pred_P = predict[0]
	pred_P = tf.squeeze(pred_P, [0])	
	temp_P = np.zeros_like(pred_P)
	for i in range(cell_size):
		for j in range(cell_size):
				temp_P[i][j] = label[4]
	P = tf.constant(temp_P)


	# find object exists cell mask
	object_exists_cell = np.zeros([cell_size, cell_size, 1])
	object_exists_cell_i, object_exists_cell_j = int(cell_size * ycenter / input_height), int(cell_size * xcenter / input_width)
	object_exists_cell[object_exists_cell_i][object_exists_cell_j] = 1

	coord_loss = ((tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_xcenter - xcenter) / (input_width / cell_size)) +
					tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_ycenter - ycenter) / (input_height / cell_size)) +
					tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_sqrt_w - sqrt_w)) / input_width +
					tf.nn.l2_loss(object_exists_cell * best_box_mask * (pred_sqrt_h - sqrt_h)) / input_height ) * coord_scale)
				

	# object_loss
	object_loss =  tf.reduce_mean(object_exists_cell * best_box_mask * object_scale * tf.nn.sigmoid_cross_entropy_with_logits(C_label, pred_C))
		
	# noobject_loss
	# object lossì™€ noobject lossì˜ ì°¨ì´ëŠ” indicator functionì´ë‹¤.
	noobject_loss = tf.reduce_mean((1 - object_exists_cell) * best_box_mask * tf.nn.sigmoid_cross_entropy_with_logits(C_label, pred_C) * noobject_scale)


	# class loss 
	class_loss = tf.reduce_mean(object_exists_cell * class_scale * tf.nn.softmax_cross_entropy_with_logits(P, pred_P))

	# sum every loss
	total_loss = coord_loss + object_loss + noobject_loss + class_loss
	
	
	return total_loss, coord_loss, object_loss, noobject_loss, class_loss

```





**detail**

- line 71  **coord_loss** :   

  `tf.nn.l2_loss(t)` : output = sum(t ** 2) / 2

  `object_exists_cell * best_box_mask` : ğŸ™^{obj}_{ij} ê³„ì‚° ì‹

  `(input_width / cell_size)` : cellì„ ê¸°ì¤€ìœ¼ë¡œ nomalizeëœ ì¢Œí‘œ ê³„ì‚°ì„ ìœ„í•œ ì‹

  `input_width` : imageë¥¼ ê¸°ì¤€ìœ¼ë¡œ normalizeë¡œ í‘œí˜„

- line 82  **noobject_loss** 

  `(1 - object_exists_cell)` : objectê°€ ì—†ëŠ” ì…€ì—ë§Œ 1ì˜ ê°’ì´ ë‚¨ëŠ”ë‹¤.

  objectê°€ ì—†ëŠ” cellì—ì„œëŠ” label confidenceê°€ ì—†ê¸° ë•Œë¬¸ì— `0 - pred_C`
